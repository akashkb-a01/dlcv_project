
# Defense against Adversarial Attacks

Deep Neural Networks are notoriously known for being very overconfident in their predictions. Szegedy et. al. discovered that Deep Neural Networks can be fooled into making wrong predictions by adding small perturbations to the original image.